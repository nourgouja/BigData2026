{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3360e2c6",
   "metadata": {},
   "source": [
    "# üáµüá∏ Gaza YouTube Analytics Dashboard\n",
    "\n",
    "## Interactive Visualization of Hadoop/PySpark Results\n",
    "\n",
    "**Data Source**: HDFS Processed Analytics  \n",
    "**Processing**: PySpark on Hadoop Docker Cluster  \n",
    "**Visualization**: Plotly Interactive Charts\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0067d5",
   "metadata": {},
   "source": [
    "## üìã Setup & Imports\n",
    "\n",
    "Install required packages if needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66a9393b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to install dependencies\n",
    "# !pip install pandas plotly wordcloud pyarrow pillow kaleido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36eca6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è WordCloud not available. Install with: pip install wordcloud\n",
      "‚úÖ Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# WordCloud for keyword visualization\n",
    "try:\n",
    "    from wordcloud import WordCloud\n",
    "    import matplotlib.pyplot as plt\n",
    "    WORDCLOUD_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è WordCloud not available. Install with: pip install wordcloud\")\n",
    "    WORDCLOUD_AVAILABLE = False\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Palestinian flag colors\n",
    "COLORS = {\n",
    "    'black': '#000000',\n",
    "    'white': '#FFFFFF',\n",
    "    'green': '#007A3D',\n",
    "    'red': '#CE1126'\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7f8f2a",
   "metadata": {},
   "source": [
    "## üìÇ Load Data from HDFS Results\n",
    "\n",
    "Loading CSV and Parquet files downloaded from Hadoop cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c49223ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Loading datasets...\n",
      "\n",
      "üìà Dataset Status:\n",
      "   ‚ùå Top Channels: Not found\n",
      "   ‚ùå Temporal Trends: Not found\n",
      "   ‚ùå Keywords: Not found\n",
      "   ‚ùå Viral Videos: Not found\n",
      "   ‚ùå Sentiment Analysis: Not found\n",
      "   ‚ùå Channel Sentiment: Not found\n",
      "\n",
      "‚úÖ Data loading complete!\n"
     ]
    }
   ],
   "source": [
    "# Data directory\n",
    "DATA_DIR = \"./hdfs_results\"\n",
    "\n",
    "# Helper function to load CSV from nested directories\n",
    "def load_csv_from_dir(pattern):\n",
    "    \"\"\"Load CSV from directory (handles Spark output structure)\"\"\"\n",
    "    csv_files = glob.glob(f\"{DATA_DIR}/{pattern}/*.csv\")\n",
    "    if not csv_files:\n",
    "        csv_files = glob.glob(f\"{DATA_DIR}/{pattern}.csv\")\n",
    "    if csv_files:\n",
    "        return pd.read_csv(csv_files[0])\n",
    "    return None\n",
    "\n",
    "# Helper function to load Parquet\n",
    "def load_parquet_from_dir(pattern):\n",
    "    \"\"\"Load Parquet from directory\"\"\"\n",
    "    parquet_path = f\"{DATA_DIR}/{pattern}.parquet\"\n",
    "    csv_path = f\"{DATA_DIR}/{pattern}.csv\"\n",
    "    \n",
    "    if os.path.exists(parquet_path):\n",
    "        return pd.read_parquet(parquet_path)\n",
    "    elif os.path.exists(csv_path):\n",
    "        return pd.read_csv(csv_path)\n",
    "    return None\n",
    "\n",
    "# Load all datasets\n",
    "print(\"üìä Loading datasets...\")\n",
    "\n",
    "df_top_channels = load_parquet_from_dir(\"df_top_channels\") or load_csv_from_dir(\"df_top_channels\")\n",
    "df_trends = load_csv_from_dir(\"df_trends\")\n",
    "df_keywords = load_csv_from_dir(\"df_keywords\")\n",
    "df_viral = load_csv_from_dir(\"df_viral\")\n",
    "df_sentiment = load_parquet_from_dir(\"df_sentiment\") or load_csv_from_dir(\"df_sentiment\")\n",
    "df_channel_sentiment = load_parquet_from_dir(\"df_channel_sentiment\")\n",
    "\n",
    "# Display loading status\n",
    "datasets = {\n",
    "    \"Top Channels\": df_top_channels,\n",
    "    \"Temporal Trends\": df_trends,\n",
    "    \"Keywords\": df_keywords,\n",
    "    \"Viral Videos\": df_viral,\n",
    "    \"Sentiment Analysis\": df_sentiment,\n",
    "    \"Channel Sentiment\": df_channel_sentiment\n",
    "}\n",
    "\n",
    "print(\"\\nüìà Dataset Status:\")\n",
    "for name, df in datasets.items():\n",
    "    if df is not None:\n",
    "        print(f\"   ‚úÖ {name}: {len(df)} records\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå {name}: Not found\")\n",
    "\n",
    "print(\"\\n‚úÖ Data loading complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c124ccb6",
   "metadata": {},
   "source": [
    "## üìä Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17e37fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample data\n",
    "if df_top_channels is not None:\n",
    "    print(\"üèÜ TOP CHANNELS SAMPLE:\")\n",
    "    display(df_top_channels.head())\n",
    "\n",
    "if df_sentiment is not None:\n",
    "    print(\"\\nüí≠ SENTIMENT ANALYSIS SAMPLE:\")\n",
    "    display(df_sentiment.head())\n",
    "    \n",
    "    # Sentiment distribution\n",
    "    print(\"\\nüìä Sentiment Distribution:\")\n",
    "    display(df_sentiment['sentiment_label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6991b266",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Visualization 1: Top Channels by Engagement\n",
    "\n",
    "Interactive bar chart showing the most engaging YouTube channels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea72828a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Top channels data not available\n"
     ]
    }
   ],
   "source": [
    "if df_top_channels is not None:\n",
    "    # Sort by engagement\n",
    "    df_plot = df_top_channels.sort_values('avg_engagement', ascending=True).tail(10)\n",
    "    \n",
    "    # Create horizontal bar chart\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_trace(go.Bar(\n",
    "        y=df_plot['channel'],\n",
    "        x=df_plot['avg_engagement'],\n",
    "        orientation='h',\n",
    "        marker=dict(\n",
    "            color=df_plot['avg_engagement'],\n",
    "            colorscale=[[0, COLORS['green']], [0.5, COLORS['black']], [1, COLORS['red']]],\n",
    "            showscale=True,\n",
    "            colorbar=dict(title=\"Engagement\")\n",
    "        ),\n",
    "        text=df_plot['avg_engagement'].round(2),\n",
    "        textposition='outside',\n",
    "        hovertemplate='<b>%{y}</b><br>Engagement: %{x:.2f}<br>Videos: %{customdata[0]}<br>Total Views: %{customdata[1]:,}<extra></extra>',\n",
    "        customdata=df_plot[['total_videos', 'total_views']].values\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=dict(\n",
    "            text=\"üèÜ Top 10 YouTube Channels by Engagement Rate\",\n",
    "            font=dict(size=20, color=COLORS['black'], family='Arial Black')\n",
    "        ),\n",
    "        xaxis_title=\"Average Engagement Score\",\n",
    "        yaxis_title=\"Channel\",\n",
    "        template=\"plotly_white\",\n",
    "        height=600,\n",
    "        showlegend=False,\n",
    "        font=dict(size=12)\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"‚ùå Top channels data not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5331c4f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìà Visualization 2: Temporal Trends - Views Over Time\n",
    "\n",
    "Time series showing weekly view trends since October 2023:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "007e51c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Trends data not available\n"
     ]
    }
   ],
   "source": [
    "if df_trends is not None:\n",
    "    # Create a date column from year and week\n",
    "    df_trends['date'] = pd.to_datetime(df_trends['year'].astype(str) + '-W' + \n",
    "                                       df_trends['week'].astype(str) + '-1', format='%Y-W%W-%w')\n",
    "    df_trends = df_trends.sort_values('date')\n",
    "    \n",
    "    # Create subplots for views and engagement\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=1,\n",
    "        subplot_titles=(\"Weekly Total Views\", \"Weekly Average Engagement\"),\n",
    "        vertical_spacing=0.12,\n",
    "        specs=[[{\"secondary_y\": False}], [{\"secondary_y\": False}]]\n",
    "    )\n",
    "    \n",
    "    # Views trace\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df_trends['date'],\n",
    "            y=df_trends['total_views'],\n",
    "            mode='lines+markers',\n",
    "            name='Total Views',\n",
    "            line=dict(color=COLORS['green'], width=3),\n",
    "            marker=dict(size=8, color=COLORS['red'], line=dict(color='white', width=2)),\n",
    "            fill='tozeroy',\n",
    "            fillcolor='rgba(0, 122, 61, 0.2)',\n",
    "            hovertemplate='Week: %{x|%Y-%m-%d}<br>Views: %{y:,}<extra></extra>'\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # Engagement trace\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df_trends['date'],\n",
    "            y=df_trends['avg_engagement'],\n",
    "            mode='lines+markers',\n",
    "            name='Avg Engagement',\n",
    "            line=dict(color=COLORS['red'], width=3),\n",
    "            marker=dict(size=8, color=COLORS['green'], line=dict(color='white', width=2)),\n",
    "            fill='tozeroy',\n",
    "            fillcolor='rgba(206, 17, 38, 0.2)',\n",
    "            hovertemplate='Week: %{x|%Y-%m-%d}<br>Engagement: %{y:.2f}<extra></extra>'\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=dict(\n",
    "            text=\"üìÖ Gaza YouTube Analytics - Temporal Trends (Weekly)\",\n",
    "            font=dict(size=22, color=COLORS['black'], family='Arial Black')\n",
    "        ),\n",
    "        template=\"plotly_white\",\n",
    "        height=800,\n",
    "        showlegend=True,\n",
    "        hovermode='x unified'\n",
    "    )\n",
    "    \n",
    "    fig.update_xaxes(title_text=\"Date\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Total Views\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Avg Engagement\", row=2, col=1)\n",
    "    \n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"‚ùå Trends data not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4255a64",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚òÅÔ∏è Visualization 3: Keyword WordCloud\n",
    "\n",
    "Visual representation of the most frequent keywords from video titles/descriptions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "211274ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Keywords data not available\n"
     ]
    }
   ],
   "source": [
    "if df_keywords is not None and WORDCLOUD_AVAILABLE:\n",
    "    # Create word frequency dictionary\n",
    "    word_freq = dict(zip(df_keywords['word'], df_keywords['count']))\n",
    "    \n",
    "    # Generate word cloud with Palestinian flag colors\n",
    "    wordcloud = WordCloud(\n",
    "        width=1200,\n",
    "        height=600,\n",
    "        background_color='white',\n",
    "        colormap='RdYlGn',  # Red-Yellow-Green\n",
    "        max_words=50,\n",
    "        relative_scaling=0.5,\n",
    "        min_font_size=10\n",
    "    ).generate_from_frequencies(word_freq)\n",
    "    \n",
    "    # Display\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title('‚òÅÔ∏è Top 50 Keywords - Gaza YouTube Videos', \n",
    "              fontsize=20, fontweight='bold', pad=20)\n",
    "    plt.tight_layout(pad=0)\n",
    "    plt.show()\n",
    "    \n",
    "elif df_keywords is not None:\n",
    "    # Fallback: Bar chart if WordCloud not available\n",
    "    fig = px.bar(\n",
    "        df_keywords.head(30),\n",
    "        x='count',\n",
    "        y='word',\n",
    "        orientation='h',\n",
    "        title='üî§ Top 30 Keywords',\n",
    "        labels={'count': 'Frequency', 'word': 'Keyword'},\n",
    "        color='count',\n",
    "        color_continuous_scale=[[0, COLORS['green']], [1, COLORS['red']]]\n",
    "    )\n",
    "    fig.update_layout(height=800, showlegend=False)\n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"‚ùå Keywords data not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e12870",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ü•ß Visualization 4: Sentiment Distribution\n",
    "\n",
    "Pie chart showing the distribution of positive, neutral, and negative sentiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ecd890a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Sentiment data not available\n"
     ]
    }
   ],
   "source": [
    "if df_sentiment is not None:\n",
    "    # Calculate sentiment distribution\n",
    "    sentiment_counts = df_sentiment['sentiment_label'].value_counts().reset_index()\n",
    "    sentiment_counts.columns = ['sentiment', 'count']\n",
    "    \n",
    "    # Define colors for sentiments\n",
    "    sentiment_colors = {\n",
    "        'positive': COLORS['green'],\n",
    "        'neutral': '#888888',\n",
    "        'negative': COLORS['red']\n",
    "    }\n",
    "    colors = [sentiment_colors.get(s, '#888888') for s in sentiment_counts['sentiment']]\n",
    "    \n",
    "    # Create pie chart\n",
    "    fig = go.Figure(data=[go.Pie(\n",
    "        labels=sentiment_counts['sentiment'],\n",
    "        values=sentiment_counts['count'],\n",
    "        hole=0.4,\n",
    "        marker=dict(colors=colors, line=dict(color='white', width=3)),\n",
    "        textinfo='label+percent+value',\n",
    "        textfont=dict(size=14, color='white', family='Arial Black'),\n",
    "        hovertemplate='<b>%{label}</b><br>Count: %{value:,}<br>Percentage: %{percent}<extra></extra>'\n",
    "    )])\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=dict(\n",
    "            text=\"üí≠ Sentiment Analysis Distribution\",\n",
    "            font=dict(size=22, color=COLORS['black'], family='Arial Black')\n",
    "        ),\n",
    "        annotations=[dict(\n",
    "            text=f\"Total<br>{sentiment_counts['count'].sum():,}\",\n",
    "            x=0.5, y=0.5,\n",
    "            font_size=16,\n",
    "            showarrow=False\n",
    "        )],\n",
    "        height=600\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    # Additional sentiment statistics\n",
    "    if 'sentiment_score' in df_sentiment.columns:\n",
    "        print(\"\\nüìä Sentiment Statistics:\")\n",
    "        print(f\"   Average Sentiment Score: {df_sentiment['sentiment_score'].mean():.3f}\")\n",
    "        print(f\"   Median Sentiment Score: {df_sentiment['sentiment_score'].median():.3f}\")\n",
    "        print(f\"   Std Deviation: {df_sentiment['sentiment_score'].std():.3f}\")\n",
    "else:\n",
    "    print(\"‚ùå Sentiment data not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3bd2a9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üî• Visualization 5: Viral Videos Analysis\n",
    "\n",
    "Top viral videos with over 1 million views:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15c53f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå No viral videos data available\n"
     ]
    }
   ],
   "source": [
    "if df_viral is not None and len(df_viral) > 0:\n",
    "    # Take top 15 viral videos\n",
    "    df_viral_top = df_viral.sort_values('views', ascending=False).head(15)\n",
    "    \n",
    "    # Create bubble chart\n",
    "    fig = px.scatter(\n",
    "        df_viral_top,\n",
    "        x='likes',\n",
    "        y='views',\n",
    "        size='comments',\n",
    "        color='engagement',\n",
    "        hover_data=['title', 'channel'],\n",
    "        title=\"üî• Viral Videos: Views vs Likes (bubble size = comments)\",\n",
    "        labels={'views': 'Total Views', 'likes': 'Total Likes', 'engagement': 'Engagement'},\n",
    "        color_continuous_scale=[[0, COLORS['green']], [0.5, '#FFD700'], [1, COLORS['red']]],\n",
    "        size_max=60\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        height=700,\n",
    "        template=\"plotly_white\",\n",
    "        font=dict(size=12)\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    # Display viral videos table\n",
    "    print(\"\\nüèÜ TOP VIRAL VIDEOS:\")\n",
    "    display(df_viral_top[['title', 'channel', 'views', 'likes', 'comments']].head(10))\n",
    "else:\n",
    "    print(\"‚ùå No viral videos data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846bf226",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üñºÔ∏è HDFS Web UI Screenshots\n",
    "\n",
    "### Browse HDFS Files\n",
    "\n",
    "Access the Hadoop HDFS Web UI to view your processed files:\n",
    "\n",
    "**üåê HDFS NameNode UI**: [http://localhost:9870](http://localhost:9870)\n",
    "\n",
    "**üìÇ Browse Files**: [http://localhost:9870/explorer.html#/processed/gaza_analytics](http://localhost:9870/explorer.html#/processed/gaza_analytics)\n",
    "\n",
    "---\n",
    "\n",
    "### Screenshot 1: HDFS File Browser\n",
    "\n",
    "Navigate to `/processed/gaza_analytics` to see your Parquet and CSV output files:\n",
    "\n",
    "```\n",
    "HDFS Path: /processed/gaza_analytics/\n",
    "‚îú‚îÄ‚îÄ df_top_channels.parquet/\n",
    "‚îú‚îÄ‚îÄ df_trends.csv/\n",
    "‚îú‚îÄ‚îÄ df_sentiment.parquet/\n",
    "‚îú‚îÄ‚îÄ df_viral.csv/\n",
    "‚îú‚îÄ‚îÄ df_keywords.csv/\n",
    "‚îî‚îÄ‚îÄ df_channel_sentiment.parquet/\n",
    "```\n",
    "\n",
    "![HDFS File Browser](http://localhost:9870/static/dfs-dust.css)\n",
    "\n",
    "---\n",
    "\n",
    "### Screenshot 2: File Details\n",
    "\n",
    "Click on any file to view:\n",
    "- File size\n",
    "- Block size\n",
    "- Replication factor\n",
    "- Permissions\n",
    "- Block locations\n",
    "\n",
    "---\n",
    "\n",
    "### How to Take Screenshots:\n",
    "\n",
    "1. **Open HDFS UI**: Navigate to [http://localhost:9870](http://localhost:9870)\n",
    "2. **Browse Files**: Click \"Utilities\" ‚Üí \"Browse the file system\"\n",
    "3. **Navigate**: Go to `/processed/gaza_analytics`\n",
    "4. **Screenshot**: Take screenshots of:\n",
    "   - File listing page\n",
    "   - Individual file details\n",
    "   - Cluster overview\n",
    "5. **Embed**: Save images and add to notebook:\n",
    "\n",
    "```python\n",
    "from IPython.display import Image, display\n",
    "display(Image('hdfs_screenshot.png'))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb068f6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba3e2656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
      "‚ïë           GAZA YOUTUBE ANALYTICS - SUMMARY REPORT              ‚ïë\n",
      "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
      "\n",
      "‚úÖ Dashboard generation complete!\n",
      "üåê Access HDFS UI: http://localhost:9870\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\")\n",
    "print(\"‚ïë           GAZA YOUTUBE ANALYTICS - SUMMARY REPORT              ‚ïë\")\n",
    "print(\"‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\")\n",
    "print()\n",
    "\n",
    "if df_sentiment is not None:\n",
    "    total_videos = len(df_sentiment)\n",
    "    total_views = df_sentiment['views'].sum() if 'views' in df_sentiment.columns else 0\n",
    "    total_likes = df_sentiment['likes'].sum() if 'likes' in df_sentiment.columns else 0\n",
    "    avg_sentiment = df_sentiment['sentiment_score'].mean() if 'sentiment_score' in df_sentiment.columns else 0\n",
    "    \n",
    "    print(f\"üìπ Total Videos Analyzed: {total_videos:,}\")\n",
    "    print(f\"üëÅÔ∏è  Total Views: {total_views:,}\")\n",
    "    print(f\"üëç Total Likes: {total_likes:,}\")\n",
    "    print(f\"üìä Average Sentiment: {avg_sentiment:.3f}\")\n",
    "    print()\n",
    "\n",
    "if df_viral is not None:\n",
    "    viral_count = len(df_viral)\n",
    "    print(f\"üî• Viral Videos (>1M views): {viral_count:,}\")\n",
    "    print()\n",
    "\n",
    "if df_top_channels is not None:\n",
    "    top_channel = df_top_channels.iloc[0]\n",
    "    print(f\"üèÜ Top Channel: {top_channel['channel']}\")\n",
    "    print(f\"   Videos: {top_channel['total_videos']}\")\n",
    "    print(f\"   Engagement: {top_channel['avg_engagement']:.2f}\")\n",
    "    print()\n",
    "\n",
    "print(\"‚úÖ Dashboard generation complete!\")\n",
    "print(\"üåê Access HDFS UI: http://localhost:9870\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b906aa",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üíæ Export Visualizations\n",
    "\n",
    "Save all charts as static images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73291f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí° Tip: Uncomment code above to export static images\n"
     ]
    }
   ],
   "source": [
    "# Uncomment to save plots as images\n",
    "# Note: Requires kaleido: pip install kaleido\n",
    "\n",
    "# if df_top_channels is not None:\n",
    "#     fig.write_image(\"viz_top_channels.png\", width=1200, height=800)\n",
    "#     print(\"‚úÖ Saved: viz_top_channels.png\")\n",
    "\n",
    "# if df_trends is not None:\n",
    "#     fig.write_image(\"viz_trends.png\", width=1200, height=800)\n",
    "#     print(\"‚úÖ Saved: viz_trends.png\")\n",
    "\n",
    "print(\"üí° Tip: Uncomment code above to export static images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a2f15b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéì Notes & Documentation\n",
    "\n",
    "### Data Pipeline:\n",
    "1. **Collection**: YouTube API ‚Üí `gaza_videos.json`\n",
    "2. **Ingestion**: Local ‚Üí HDFS (`hdfs://localhost:9000/raw/youtube/`)\n",
    "3. **Processing**: PySpark (`pyspark_gaza.py`)\n",
    "   - Data cleaning & transformation\n",
    "   - NLP sentiment analysis (VADER)\n",
    "   - Keyword extraction (TF-IDF)\n",
    "   - Aggregations & analytics\n",
    "4. **Storage**: HDFS Parquet/CSV (`/processed/gaza_analytics/`)\n",
    "5. **Visualization**: This Jupyter notebook\n",
    "\n",
    "### Technologies:\n",
    "- **Big Data**: Hadoop HDFS, Apache Spark\n",
    "- **Processing**: PySpark (Python API for Spark)\n",
    "- **NLP**: NLTK, VADER Sentiment Analysis\n",
    "- **Visualization**: Plotly, Matplotlib, WordCloud\n",
    "- **Container**: Docker (Hadoop cluster)\n",
    "\n",
    "### Key Metrics:\n",
    "- **Engagement Rate**: `(views / (likes + comments + 1)) * 100`\n",
    "- **Sentiment Score**: VADER compound score (-1 to +1)\n",
    "- **Viral Threshold**: Videos with >1,000,000 views\n",
    "\n",
    "---\n",
    "\n",
    "**üáµüá∏ Gaza YouTube Analytics Dashboard**  \n",
    "*Built with Hadoop, PySpark, and Plotly*  \n",
    "*Data Analysis for Social Impact*\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
