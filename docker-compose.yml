version: '3.8'

services:
  namenode:
    image: razer99/hadoop-cluster-mouin-boubakri:latest
    container_name: namenode
    hostname: namenode
    environment:
      - HADOOP_ROLE=namenode
      - CLUSTER_NAME=gaza-youtube-analytics
    ports:
      - "9870:9870"   # NameNode Web UI
      - "9000:9000"   # HDFS IPC
      - "8088:8088"   # ResourceManager Web UI
    volumes:
      - namenode_data:/hadoop/dfs/name
      - ./hadoop-configs:/opt/hadoop/etc/hadoop
      - ./start-hadoop.sh:/start-hadoop.sh
      - ./pyspark_gaza.py:/opt/pyspark_gaza.py
    networks:
      - hadoop-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9870"]
      interval: 30s
      timeout: 10s
      retries: 3
    command: ["/bin/bash", "/start-hadoop.sh"]

  secondarynamenode:
    image: razer99/hadoop-cluster-mouin-boubakri:latest
    container_name: secondarynamenode
    hostname: secondarynamenode
    environment:
      - HADOOP_ROLE=secondarynamenode
      - CLUSTER_NAME=gaza-youtube-analytics
    ports:
      - "9868:9868"   # Secondary NameNode Web UI
    volumes:
      - secondarynamenode_data:/hadoop/dfs/namesecondary
      - ./hadoop-configs:/opt/hadoop/etc/hadoop
      - ./start-hadoop.sh:/start-hadoop.sh
    networks:
      - hadoop-network
    depends_on:
      - namenode
    command: ["/bin/bash", "/start-hadoop.sh"]

  datanode1:
    image: razer99/hadoop-cluster-mouin-boubakri:latest
    container_name: datanode1
    hostname: datanode1
    environment:
      - HADOOP_ROLE=datanode
      - CLUSTER_NAME=gaza-youtube-analytics
    ports:
      - "9864:9864"   # DataNode Web UI
    volumes:
      - datanode1_data:/hadoop/dfs/data
      - ./hadoop-configs:/opt/hadoop/etc/hadoop
      - ./start-hadoop.sh:/start-hadoop.sh
    networks:
      - hadoop-network
    depends_on:
      - namenode
    command: ["/bin/bash", "/start-hadoop.sh"]

  datanode2:
    image: razer99/hadoop-cluster-mouin-boubakri:latest
    container_name: datanode2
    hostname: datanode2
    environment:
      - HADOOP_ROLE=datanode
      - CLUSTER_NAME=gaza-youtube-analytics
    ports:
      - "9865:9864"   # DataNode Web UI
    volumes:
      - datanode2_data:/hadoop/dfs/data
      - ./hadoop-configs:/opt/hadoop/etc/hadoop
      - ./start-hadoop.sh:/start-hadoop.sh
    networks:
      - hadoop-network
    depends_on:
      - namenode
    command: ["/bin/bash", "/start-hadoop.sh"]

  datanode3:
    image: razer99/hadoop-cluster-mouin-boubakri:latest
    container_name: datanode3
    hostname: datanode3
    environment:
      - HADOOP_ROLE=datanode
      - CLUSTER_NAME=gaza-youtube-analytics
    ports:
      - "9866:9864"   # DataNode Web UI
    volumes:
      - datanode3_data:/hadoop/dfs/data
      - ./hadoop-configs:/opt/hadoop/etc/hadoop
      - ./start-hadoop.sh:/start-hadoop.sh
    networks:
      - hadoop-network
    depends_on:
      - namenode
    command: ["/bin/bash", "/start-hadoop.sh"]

  datanode4:
    image: razer99/hadoop-cluster-mouin-boubakri:latest
    container_name: datanode4
    hostname: datanode4
    environment:
      - HADOOP_ROLE=datanode
      - CLUSTER_NAME=gaza-youtube-analytics
    ports:
      - "9867:9864"   # DataNode Web UI
    volumes:
      - datanode4_data:/hadoop/dfs/data
      - ./hadoop-configs:/opt/hadoop/etc/hadoop
      - ./start-hadoop.sh:/start-hadoop.sh
    networks:
      - hadoop-network
    depends_on:
      - namenode
    command: ["/bin/bash", "/start-hadoop.sh"]

  spark-master:
    image: bitnami/spark:3.5
    container_name: spark-master
    hostname: spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=spark-master
      - SPARK_MASTER_PORT=7077
      - SPARK_MASTER_WEBUI_PORT=8080
    ports:
      - "8080:8080"   # Spark Master Web UI
      - "7077:7077"   # Spark Master
    volumes:
      - ./pyspark_gaza.py:/opt/pyspark_gaza.py
      - spark_master_data:/opt/spark-data
    networks:
      - hadoop-network
    command: ["/opt/bitnami/scripts/spark/run.sh"]

  spark-worker-1:
    image: bitnami/spark:3.5
    container_name: spark-worker-1
    hostname: spark-worker-1
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=4G
      - SPARK_WORKER_CORES=2
    ports:
      - "8081:8081"   # Spark Worker Web UI
    volumes:
      - spark_worker1_data:/opt/spark-data
    networks:
      - hadoop-network
    depends_on:
      - spark-master

  spark-worker-2:
    image: bitnami/spark:3.5
    container_name: spark-worker-2
    hostname: spark-worker-2
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=4G
      - SPARK_WORKER_CORES=2
    ports:
      - "8082:8081"   # Spark Worker Web UI
    volumes:
      - spark_worker2_data:/opt/spark-data
    networks:
      - hadoop-network
    depends_on:
      - spark-master

networks:
  hadoop-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.25.0.0/16

volumes:
  namenode_data:
    driver: local
  secondarynamenode_data:
    driver: local
  datanode1_data:
    driver: local
  datanode2_data:
    driver: local
  datanode3_data:
    driver: local
  datanode4_data:
    driver: local
  spark_master_data:
    driver: local
  spark_worker1_data:
    driver: local
  spark_worker2_data:
    driver: local
